{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import time\n",
    "from splinter import browser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import urllib.parse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save html in txt file in case I need it.\n",
    "BASE_URL = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "FILE_NAME = \"html-requests.txt\"\n",
    "\n",
    "html = requests.get(BASE_URL).text\n",
    "with open(FILE_NAME, \"w+\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "FILE = \"html-selenium.txt\"\n",
    "FILE_WAIT = \"html-selenium-wait.txt\"\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(BASE_URL)\n",
    "html = driver.page_source\n",
    "\n",
    "with open(FILE, \"w+\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "driver.get(BASE_URL)\n",
    "html = driver.page_source\n",
    "driver.implicitly_wait(10)\n",
    "driver.close()\n",
    "\n",
    "with open(FILE_WAIT, \"w+\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars News\n",
    "\n",
    "### Collect the latest News Title and Paragraph Text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Title: The MarCO Mission Comes to an End\n",
      "Teaser: The pair of briefcase-sized satellites made history when they sailed past Mars in 2019.\n"
     ]
    }
   ],
   "source": [
    "# Since requests.get wasn't bringing the latest news, I used selenium.\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(url)\n",
    "html = driver.page_source\n",
    "\n",
    "# The driver opened the page and the soup brought the latest news title\n",
    "soup = bs(html, \"html.parser\")\n",
    "news_title = (soup.find(\"div\", class_=\"list_text\")).find(\"a\").text\n",
    "print(f\"News Title: {news_title}\")\n",
    "\n",
    "# Find the news url\n",
    "teaser_url = (\n",
    "    \"https://mars.nasa.gov/news/\" + soup.find(\"div\", class_=\"list_text\").a[\"href\"]\n",
    ")\n",
    "\n",
    "# Soup brought the teaser\n",
    "r = requests.get(teaser_url)\n",
    "html = r.text\n",
    "soup = bs(html, \"html.parser\")\n",
    "teaser = (soup.find(\"div\", class_=\"wysiwyg_content\")).find(\"p\").text\n",
    "\n",
    "print(f\"Teaser: {teaser}\")\n",
    "\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA17900_hires.jpg\n"
     ]
    }
   ],
   "source": [
    "# Connect to a url to grab NASA's featured Mars image\n",
    "\n",
    "# Use selenium to navegate to the page with the image\n",
    "driver = webdriver.Firefox()\n",
    "url_image = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "driver.get(url_image)\n",
    "time.sleep(1)\n",
    "\n",
    "elem = driver.find_element_by_id(\"full_image\")\n",
    "elem.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# Navigate to \"more info\" web site, where the full image URL is\n",
    "elem = driver.find_element_by_link_text(\"more info\")\n",
    "elem.click()\n",
    "time.sleep(1)\n",
    "\n",
    "# Get the \"more info\" page URL to parse and find the image in full resolution\n",
    "url_more_info = driver.current_url\n",
    "\n",
    "# Use requests and soup to return the image url\n",
    "r = requests.get(url_more_info)\n",
    "html = r.text\n",
    "soup = bs(html, \"html.parser\")\n",
    "featured_image_url = (\n",
    "    \"https://www.jpl.nasa.gov\" + soup.find(\"figure\", class_=\"lede\").a[\"href\"]\n",
    ")\n",
    "print(featured_image_url)\n",
    "\n",
    "# Close the browser\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather today in Mars is: \n",
      "InSight sol 445 (2020-02-26) low -92.8ºC (-135.0ºF) high -12.8ºC (8.9ºF)\n",
      "winds from the SSE at 5.9 m/s (13.3 mph) gusting to 21.1 m/s (47.3 mph)\n",
      "pressure at 6.30 hPapic.twitter.com/ihFGVkib6L\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mars Weather\n",
    "# Visit https://twitter.com/marswxreport?lang=en and scrape the latest Mars weather tweet from the page.\n",
    "# Save the tweet text for the weather report as a variable called `mars_weather`.\n",
    "\n",
    "# Connect to url for Mars Weather Twitter page\n",
    "\n",
    "url_twitter = \"https://twitter.com/marswxreport?lang=en\"\n",
    "\n",
    "# Create a Beautiful Soup object\n",
    "r = requests.get(url_twitter)\n",
    "html = r.text\n",
    "soup = bs(html, \"html.parser\")\n",
    "mars_weather = soup.find_all(\"div\", class_=\"js-tweet-text-container\")\n",
    "\n",
    "# find the first actual weather tweet\n",
    "\n",
    "mars_weather = mars_weather[0].text\n",
    "\n",
    "print(f\"The weather today in Mars is: {mars_weather}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b8be1a584d6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl_facts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://space-facts.com/mars/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmars_facts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_facts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0mdisplayed_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0mretained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplayed_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_LXML\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lxml not found, please install it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_valid_parsers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: lxml not found, please install it"
     ]
    }
   ],
   "source": [
    "################# Mars Facts - use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "#  Use Pandas to convert the data to a HTML table string.\n",
    "\n",
    "url_facts = \"http://space-facts.com/mars/\"\n",
    "mars_facts = pd.read_html(url_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain high resolution images for each of Mar's hemispheres.\n",
    "# Save both the image url string for the full resolution hemisphere image,\n",
    "# and the Hemisphere title containing the hemisphere name.\n",
    "# Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "# Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "# set url and the driver\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "url_hem = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "driver.get(url_hem)\n",
    "html = driver.page_source\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# scrape page into Soup to get the hemispheres names\n",
    "\n",
    "soup = bs(html, \"html.parser\")\n",
    "\n",
    "title_all = soup.find_all(\"h3\")\n",
    "title = [result.text for result in title_all]\n",
    "# print(title)\n",
    "\n",
    "# # hemispheres = driver.find_elements_by_class_name(\"item\")\n",
    "# title = driver.find_element_by_xpath('//*[@id=\"product-section\"]/div[2]/div/a').text\n",
    "# print(title)\n",
    "\n",
    "\n",
    "hemispheres_dict = []\n",
    "\n",
    "for item in driver.find_elements_by_class_name(\"item\"):\n",
    "    img_url = driver.find_element_by_class_name(\"thumb\").text\n",
    "print(img_url)\n",
    "\n",
    "\n",
    "# for item in driver.find_elements_by_class_name(\"item\"):\n",
    "#     title = driver.find_element_by_(\n",
    "#         '//*[@id=\"product-section\"]/div[2]//div/a'\n",
    "#     ).text\n",
    "#     img_url = driver.find_element_by_class_name(\n",
    "#         \"thumb\"\n",
    "#     ).text\n",
    "#     hemispheres_dict.append({\"title\": title, \"img_url\": img_url})\n",
    "\n",
    "# # (\n",
    "# #     soup.find(\"div\", class_=\"collapsible results\").find(\"div\", class_=\"item\").a[\"href\"]\n",
    "# # )\n",
    "# print(hemispheres_dict)\n",
    "\n",
    "\n",
    "# hemisphere_image_urls = []\n",
    "\n",
    "\n",
    "# Close the browser\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mars",
   "language": "python",
   "name": "mars"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
